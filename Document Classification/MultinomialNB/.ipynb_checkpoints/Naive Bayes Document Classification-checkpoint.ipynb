{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Naive Bayes Document Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This program was created by Brandon Watts and is used to classify documents using the Multinomial Naive Bayes classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start you need to create a csv file with the following structure:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Label  | Directory|\n",
    "| -------|:--------:|\n",
    "| NEWS   | Comp     |\n",
    "| COMP   | News     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we have 2 Labels (NEWS & COMP) which will map to the 2 Directoreis (News & Comp) Respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first load in dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import Tools.TextTools as TextTools\n",
    "from sklearn import metrics\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets create an array to hold the each Directories DataFrame once they are created so we can concatenate them all together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_dataframes = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to read in the csv file we made earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_mapping_df = pd.read_csv(\"mapping.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Label Directory\n",
      "0  COMP      Comp\n",
      "1  NEWS      News\n"
     ]
    }
   ],
   "source": [
    "print(documents_mapping_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to read through each row and create a Dataframe with all the files mapped to the supplied Label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in documents_mapping_df.iterrows():\n",
    "    documents_dataframes.append(TextTools.build_data_frame(row[\"Label\"], row['Directory']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[               class                                               text\n",
      "COMP/13259.txt  Comp     Cone Trees in the UGA Graphics System: Sugg...\n",
      "COMP/7183.txt   Comp     The Challenge of Deep Models, Inference Str...\n",
      "COMP/25473.txt  Comp     Extracting Multi-Dimensional Signal Feature...\n",
      "COMP/40879.txt  Comp        Instance Pruning Techniques      Abstrac...\n",
      "COMP/39955.txt  Comp     Structured Interviews on the Object-Oriente...\n",
      "COMP/23267.txt  Comp     P++: A Language for Software System Generat...\n",
      "COMP/16393.txt  Comp     Karin Petersen Kai Li   Department of Compu...\n",
      "COMP/39172.txt  Comp     Block Edit Models for Approximate String Ma...\n",
      "COMP/18209.txt  Comp     Mutable Object State for Object-Oriented Lo...\n",
      "COMP/20782.txt  Comp     High Performance Geographic Information Sys...\n",
      "COMP/23507.txt  Comp     Models for Computer Generated Parody       ...\n",
      "COMP/43032.txt  Comp     Observations and Recommendations on the Int...\n",
      "COMP/10894.txt  Comp     A Safe, Efficient Regression Test Selection...\n",
      "COMP/7502.txt   Comp     Proceedings of the First International Work...\n",
      "COMP/12049.txt  Comp     Occam's Razor: The Cutting Edge for Parser ...\n",
      "COMP/37632.txt  Comp     The Internet Software Visualization Laborat...\n",
      "COMP/9307.txt   Comp     Specifying and Adapting Object Behavior dur...\n",
      "COMP/23596.txt  Comp     The Effect of Group Size and Communication ...\n",
      "COMP/19970.txt  Comp     A New Deterministic Parallel Sorting Algori...\n",
      "COMP/one.txt    Comp     Clustering Full Text Documents        Abstr...,                      class                                               text\n",
      "NEWS/cv000_29590.txt  News  films adapted from comic books have had plenty...\n",
      "NEWS/cv013_10159.txt  News  synopsis : in this movie , steven spielberg , ...\n",
      "NEWS/cv016_4659.txt   News  carry on matron is the last great carry-on fil...\n",
      "NEWS/cv007_4968.txt   News  one of my colleagues was surprised when i told...\n",
      "NEWS/cv010_29198.txt  News  after watching \" rat race \" last week , i noti...\n",
      "NEWS/cv002_15918.txt  News  you've got mail works alot better than it dese...\n",
      "NEWS/cv003_11664.txt  News   \" jaws \" is a rare film that grabs your atten...\n",
      "NEWS/cv017_22464.txt  News  the ultimate match up between good and evil , ...\n",
      "NEWS/cv005_29443.txt  News  on june 30 , 1960 , a self-taught , idealistic...\n",
      "NEWS/cv011_12166.txt  News  i've noticed something lately that i've never ...\n",
      "NEWS/cv015_29439.txt  News  plot : a young man who loves heavy metal music...\n",
      "NEWS/cv001_18431.txt  News  every now and then a movie comes along from a ...\n",
      "NEWS/cv009_29592.txt  News  the american action film has been slowly drown...\n",
      "NEWS/cv019_14482.txt  News  there's something about ben stiller that makes...\n",
      "NEWS/cv004_11636.txt  News  moviemaking is a lot like being the general ma...\n",
      "NEWS/cv014_13924.txt  News  the police negotiator is the person with the e...\n",
      "NEWS/cv006_15448.txt  News  apparently , director tony kaye had a major ba...\n",
      "NEWS/cv008_29435.txt  News  after bloody clashes and independence won , lu...\n",
      "NEWS/cv012_29576.txt  News  synopsis : bobby garfield ( yelchin ) lives in...\n",
      "NEWS/cv020_8825.txt   News  by phil curtolo mel gibson ( braveheart ) gave...\n",
      "NEWS/cv018_20137.txt  News  having not seen , \" who framed roger rabbit \" ...]\n"
     ]
    }
   ],
   "source": [
    "print(documents_dataframes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets concatenate all these smaller DataFrames into 1 big one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = pd.concat(documents_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               class                                               text\n",
      "COMP/13259.txt  Comp     Cone Trees in the UGA Graphics System: Sugg...\n",
      "COMP/7183.txt   Comp     The Challenge of Deep Models, Inference Str...\n",
      "COMP/25473.txt  Comp     Extracting Multi-Dimensional Signal Feature...\n",
      "COMP/40879.txt  Comp        Instance Pruning Techniques      Abstrac...\n",
      "COMP/39955.txt  Comp     Structured Interviews on the Object-Oriente...\n"
     ]
    }
   ],
   "source": [
    "print(documents.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing we will do is mix up the dataframe so that the files of the same label are not right next to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = documets.reindex(np.random.permutation(documets.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     class                                               text\n",
      "NEWS/cv019_14482.txt  News  there's something about ben stiller that makes...\n",
      "COMP/23596.txt        Comp     The Effect of Group Size and Communication ...\n",
      "COMP/20782.txt        Comp     High Performance Geographic Information Sys...\n",
      "COMP/13259.txt        Comp     Cone Trees in the UGA Graphics System: Sugg...\n",
      "COMP/23507.txt        Comp     Models for Computer Generated Parody       ...\n"
     ]
    }
   ],
   "source": [
    "print(documents.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have created a file called \"TextTools\" that come with all the standard nlp pipleine components. Right now we are cleaning the text by removing uneccesary spacing, removing the stop words, and applying Lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents['text'] = documents['text'].map(lambda x: TextTools.clean_text(x)).map(lambda x: TextTools.detokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     class                                               text\n",
      "NEWS/cv019_14482.txt  News  's someth ben stiller make popular choic among...\n",
      "COMP/23596.txt        Comp  the effect group size commun mode cscw environ...\n",
      "COMP/20782.txt        Comp  high perform geograph inform system : experi s...\n",
      "COMP/13259.txt        Comp  cone tree uga graphic system : suggest robust ...\n",
      "COMP/23507.txt        Comp  model comput gener parodi abstract thi paper o...\n"
     ]
    }
   ],
   "source": [
    "print(documents.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the testing and training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = documents.iloc[:, 1].values\n",
    "y = documents.iloc[:, 0].values\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the classfiier we need to turn the text to features. We will use sklearn's 'CountVectorizer' to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 320)\t1\n",
      "  (0, 236)\t1\n",
      "  (0, 490)\t1\n",
      "  (0, 6741)\t1\n",
      "  (0, 3245)\t1\n",
      "  (0, 3928)\t1\n",
      "  (0, 6190)\t1\n",
      "  (0, 4674)\t1\n",
      "  (0, 1296)\t1\n",
      "  (0, 6867)\t1\n",
      "  (0, 2418)\t1\n",
      "  (0, 500)\t1\n",
      "  (0, 1015)\t1\n",
      "  (0, 2677)\t1\n",
      "  (0, 1174)\t1\n",
      "  (0, 6673)\t1\n",
      "  (0, 5470)\t1\n",
      "  (0, 5801)\t1\n",
      "  (0, 3723)\t1\n",
      "  (0, 6124)\t1\n",
      "  (0, 4059)\t1\n",
      "  (0, 1753)\t1\n",
      "  (0, 1672)\t1\n",
      "  (0, 5151)\t1\n",
      "  (0, 994)\t1\n",
      "  :\t:\n",
      "  (31, 4833)\t2\n",
      "  (31, 2499)\t5\n",
      "  (31, 1585)\t1\n",
      "  (31, 2504)\t2\n",
      "  (31, 6527)\t4\n",
      "  (31, 4211)\t1\n",
      "  (31, 5817)\t1\n",
      "  (31, 4689)\t1\n",
      "  (31, 1696)\t1\n",
      "  (31, 4401)\t2\n",
      "  (31, 3597)\t1\n",
      "  (31, 4994)\t1\n",
      "  (31, 1535)\t1\n",
      "  (31, 1668)\t1\n",
      "  (31, 6725)\t2\n",
      "  (31, 5281)\t3\n",
      "  (31, 5031)\t1\n",
      "  (31, 6232)\t1\n",
      "  (31, 2806)\t1\n",
      "  (31, 3921)\t1\n",
      "  (31, 2411)\t1\n",
      "  (31, 2564)\t1\n",
      "  (31, 5016)\t1\n",
      "  (31, 1707)\t1\n",
      "  (31, 5239)\t1\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "counts = count_vectorizer.fit_transform(X_train)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = MultinomialNB()\n",
    "targets = y_train\n",
    "classifier.fit(counts, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testign the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Comp       1.00      1.00      1.00         6\n",
      "       News       1.00      1.00      1.00         3\n",
      "\n",
      "avg / total       1.00      1.00      1.00         9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = classifier.predict(count_vectorizer.transform(X_test))\n",
    "print(metrics.classification_report(y_test, preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
