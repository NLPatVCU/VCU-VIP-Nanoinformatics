{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Naive Bayes Document Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First we import everything we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer, f1_score, precision_score, recall_score\n",
    "import sys\n",
    "import pandas as pd\n",
    "sys.path.append('/Users/brandonwatts/Desktop/VCU-VIP-Nanoinformatics/Tools')\n",
    "from TextTools import build_data_frame, clean_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next we will define a mapping that will map an entity label to a directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Directory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NANOINF</td>\n",
       "      <td>../../Data/NanoinformaticsTXT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENV</td>\n",
       "      <td>../../Data/EnvironmentTXT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SYN</td>\n",
       "      <td>../../Data/SynthesisTXT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TOX</td>\n",
       "      <td>../../Data/ToxicologyTXT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                      Directory\n",
       "0  NANOINF  ../../Data/NanoinformaticsTXT\n",
       "1      ENV      ../../Data/EnvironmentTXT\n",
       "2      SYN        ../../Data/SynthesisTXT\n",
       "3      TOX       ../../Data/ToxicologyTXT"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_df = pd.read_csv('../../Data/mapping.csv')\n",
    "mapping_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we can obtain the documents from thier directory and place them in a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>../../Data/NanoinformaticsTXT/Tang_International Journal of Nanomedicine_2013.txt</th>\n",
       "      <td>NANOINF</td>\n",
       "      <td>tang al publisher licensee dove medical press ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../../Data/NanoinformaticsTXT/Kostoff_J.txt</th>\n",
       "      <td>NANOINF</td>\n",
       "      <td>data mining tomography office naval research n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../../Data/NanoinformaticsTXT/Chiesa_Maojo_INVE_MEM_2008.txt</th>\n",
       "      <td>NANOINF</td>\n",
       "      <td>part berlin building index automatic approach ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../../Data/NanoinformaticsTXT/Liu_Cohen_CompSciDisc_2013.txt</th>\n",
       "      <td>NANOINF</td>\n",
       "      <td>screening data analysis institute university c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../../Data/NanoinformaticsTXT/Oksel_Particuology_2015.txt</th>\n",
       "      <td>NANOINF</td>\n",
       "      <td>article contents available jo ur home page loc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      class  \\\n",
       "../../Data/NanoinformaticsTXT/Tang_Internationa...  NANOINF   \n",
       "../../Data/NanoinformaticsTXT/Kostoff_J.txt         NANOINF   \n",
       "../../Data/NanoinformaticsTXT/Chiesa_Maojo_INVE...  NANOINF   \n",
       "../../Data/NanoinformaticsTXT/Liu_Cohen_CompSci...  NANOINF   \n",
       "../../Data/NanoinformaticsTXT/Oksel_Particuolog...  NANOINF   \n",
       "\n",
       "                                                                                                 text  \n",
       "../../Data/NanoinformaticsTXT/Tang_Internationa...  tang al publisher licensee dove medical press ...  \n",
       "../../Data/NanoinformaticsTXT/Kostoff_J.txt         data mining tomography office naval research n...  \n",
       "../../Data/NanoinformaticsTXT/Chiesa_Maojo_INVE...  part berlin building index automatic approach ...  \n",
       "../../Data/NanoinformaticsTXT/Liu_Cohen_CompSci...  screening data analysis institute university c...  \n",
       "../../Data/NanoinformaticsTXT/Oksel_Particuolog...  article contents available jo ur home page loc...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getDocumentsFrom(mapping_df):\n",
    "    documents_array = []\n",
    "    for index, row in mapping_df.iterrows():\n",
    "        documents_array.append(build_data_frame(row[\"Directory\"], row['Label']))\n",
    "    return pd.concat(documents_array)\n",
    "\n",
    "documents = getDocumentsFrom(mapping_df)\n",
    "documents.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our documents are in order so we need to shuffle them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>../../Data/SynthesisTXT/Dong_J Am Chem Soc_2007.txt</th>\n",
       "      <td>SYN</td>\n",
       "      <td>cellulose dong institute department wood scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../../Data/NanoinformaticsTXT/delaIglesia_Maojo_PLoS_2014.txt</th>\n",
       "      <td>NANOINF</td>\n",
       "      <td>machine learning approach identify clinical de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../../Data/EnvironmentTXT/Zhu_Journal of Environmental Science and Health Part A_2008.txt</th>\n",
       "      <td>ENV</td>\n",
       "      <td>journal environmental science health part copy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../../Data/ToxicologyTXT/Duffin_Inhalation Toxicology_2007.txt</th>\n",
       "      <td>TOX</td>\n",
       "      <td>inhalation toxicology copyright print effects ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../../Data/SynthesisTXT/Imani_Nanoscale Res Lett_2015.txt</th>\n",
       "      <td>SYN</td>\n",
       "      <td>express open access growth novel urchin contro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      class  \\\n",
       "../../Data/SynthesisTXT/Dong_J Am Chem Soc_2007...      SYN   \n",
       "../../Data/NanoinformaticsTXT/delaIglesia_Maojo...  NANOINF   \n",
       "../../Data/EnvironmentTXT/Zhu_Journal of Enviro...      ENV   \n",
       "../../Data/ToxicologyTXT/Duffin_Inhalation Toxi...      TOX   \n",
       "../../Data/SynthesisTXT/Imani_Nanoscale Res Let...      SYN   \n",
       "\n",
       "                                                                                                 text  \n",
       "../../Data/SynthesisTXT/Dong_J Am Chem Soc_2007...  cellulose dong institute department wood scien...  \n",
       "../../Data/NanoinformaticsTXT/delaIglesia_Maojo...  machine learning approach identify clinical de...  \n",
       "../../Data/EnvironmentTXT/Zhu_Journal of Enviro...  journal environmental science health part copy...  \n",
       "../../Data/ToxicologyTXT/Duffin_Inhalation Toxi...  inhalation toxicology copyright print effects ...  \n",
       "../../Data/SynthesisTXT/Imani_Nanoscale Res Let...  express open access growth novel urchin contro...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def shuffle(docs):\n",
    "    return docs.reindex(np.random.permutation(docs.index))\n",
    "\n",
    "documents = shuffle(documents)\n",
    "documents.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The text is junk and needs to be cleaned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents['text'] = documents['text'].map(lambda x: clean_text(x))\n",
    "documents.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define our training vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = documents.iloc[:, 1].values\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y  = documents.iloc[:, 0].values\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define our Pipeine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(ngram_range=(1, 2))),\n",
    "    ('classifier', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUMBER_OF_FOLDS = 10\n",
    "scoreers = {\n",
    "        \"f1_scores\": make_scorer(f1_score, average='weighted'),\n",
    "        \"precision_scores\": make_scorer(precision_score, average='weighted'),\n",
    "        \"recall_scores\": make_scorer(recall_score, average='weighted'),\n",
    "    }\n",
    "scores = cross_validate(pipeline, X, y, cv=NUMBER_OF_FOLDS,scoring=scoreers, n_jobs=-1)\n",
    "\n",
    "f1_scores = scores['test_f1_scores']\n",
    "precision_scores = scores['test_precision_scores']\n",
    "recall_scores = scores['test_recall_scores']\n",
    "\n",
    "for x in range(NUMBER_OF_FOLDS):\n",
    "    print(\"Fold number: \", x)\n",
    "    print(\"Precision: \", precision_scores[x])\n",
    "    print(\"Recall: \", recall_scores[x])\n",
    "    print(\"F1 Score: \", f1_scores[x])\n",
    "    print(\"\\n\")\n",
    "\n",
    "print(\"Averages Across Folds\")\n",
    "print(\"Precision: \", np.mean(np.array(precision_scores)))\n",
    "print(\"Recall: \", np.mean(np.array(recall_scores)))\n",
    "print(\"F1 Score: \", np.mean(np.array(f1_scores)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
